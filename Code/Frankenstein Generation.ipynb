{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: \n",
    "        Raw text\n",
    "    Output: \n",
    "        Tokenized version of text with splits on each space\n",
    "    \"\"\"\n",
    "\n",
    "    split = [i for i in text.split(\" \") if i != \"\"]\n",
    "    lst = []\n",
    "\n",
    "    for i in split:\n",
    "        \n",
    "        app = \"\"\n",
    "        \n",
    "        for j in range(len(i)):\n",
    "            \n",
    "            #Handles splitting with punctuation\n",
    "            if i[j] in string.punctuation and app != \"\":\n",
    "                lst.append(app)\n",
    "                lst.append(i[j])\n",
    "                app = \"\"\n",
    "\n",
    "            elif i[j] in string.punctuation and app == \"\":\n",
    "                lst.append(i[j])\n",
    "                app = \"\"\n",
    "\n",
    "            else:\n",
    "                app += i[j]\n",
    "\n",
    "            if j == len(i)-1 and app != \"\":\n",
    "                lst.append(app)\n",
    "    \n",
    "    return(lst)\n",
    "\n",
    "\n",
    "def ngrams(n, tokens):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        n - Number of previous tokens to include\n",
    "        tokens - List of tokenized text\n",
    "    Output:\n",
    "        n_grams - List containing tuples with length n-1\n",
    "    \"\"\"\n",
    "    \n",
    "    n_grams = []\n",
    "    including_end = tokens + ['<END>']\n",
    "\n",
    "    for i in range(len(including_end)):\n",
    "\n",
    "        append_lst = []\n",
    "        for j in range(n-1, 0, -1):\n",
    "\n",
    "            if i-j < 0:\n",
    "                append_lst.append(\"<START>\")\n",
    "\n",
    "            else:\n",
    "                append_lst.append(including_end[i-j])\n",
    "\n",
    "        n_grams.append(tuple((tuple(append_lst), including_end[i])))\n",
    "\n",
    "    return(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramModel(object):\n",
    "\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.freqs = {}\n",
    "\n",
    "    \n",
    "    def update(self, sentence):\n",
    "        \n",
    "        \"\"\"\n",
    "        Updates the n-gram model given a new sentence\n",
    "        \"\"\"\n",
    "        ngram = ngrams(self.n, tokenize(sentence))\n",
    "\n",
    "        for (predecessor, successor) in ngram:\n",
    "\n",
    "            if (predecessor, successor) not in self.freqs.keys():\n",
    "                self.freqs[(predecessor, successor)] = 1\n",
    "\n",
    "            else:   \n",
    "                self.freqs[(predecessor, successor)] += 1\n",
    "\n",
    "    \n",
    "    def prob(self, context, token):\n",
    "        \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            context - Tuple of length n-1 giving the predecessor to the token\n",
    "            token - The token whose probability is to be computed\n",
    "        Output:\n",
    "            probability - The conditional probability that the token occurs given the context\n",
    "        \"\"\"\n",
    "        \n",
    "        #Counts number of occurences of context followed by token\n",
    "        events = sum([val for (key, val) in self.freqs.items() \n",
    "                      if key[0] == context and key[1] == token])\n",
    "        \n",
    "        #Counts total number of occurences of context\n",
    "        total = sum([val for (key, val) in self.freqs.items() \n",
    "                     if key[0] == context])\n",
    "        \n",
    "        probability = events/total\n",
    "        \n",
    "        return(probability)\n",
    "\n",
    "    \n",
    "    def random_token(self, context):\n",
    "        \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            context - Tuple of length n-1 giving the predecessor to the generated string\n",
    "        Output:\n",
    "            Random token, based on distribution of dataset given the context\n",
    "        \"\"\"\n",
    "        \n",
    "        random_num = random.random()\n",
    "        \n",
    "        #Count occurrences of successors given the context\n",
    "        context_occurences = sorted([(key[1], val) for (key, val) in self.freqs.items() \n",
    "                      if key[0] == context])\n",
    "        choices = {x[0]:x[1] for x in context_occurences}\n",
    "        \n",
    "        #Counts total number of occurences of context\n",
    "        total = sum([val for (key, val) in self.freqs.items() \n",
    "                     if key[0] == context])\n",
    "        \n",
    "        probab = 0\n",
    "        \n",
    "        for i in range(len(context_occurences)):\n",
    "\n",
    "            if i == len(context_occurences) - 1:\n",
    "                return(context_occurences[i][0])\n",
    "\n",
    "            elif probab <= random_num and  random_num < probab + (choices[context_occurences[i][0]]/total):\n",
    "                return(context_occurences[i][0])\n",
    "\n",
    "            probab += choices[context_occurences[i][0]]/total\n",
    "\n",
    "\n",
    "    def random_text(self, token_count):\n",
    "        \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            token_count - Length of the randomly generated string\n",
    "        Output:\n",
    "            string - Random string of length token_count using random_token\n",
    "        \"\"\"\n",
    "\n",
    "        string = \"\"\n",
    "        context = [\"<START>\" for i in range(self.n - 1)]\n",
    "        change = 0\n",
    "\n",
    "        for i in range(token_count):\n",
    "            \n",
    "            token = self.random_token(tuple(context))\n",
    "\n",
    "            if self.n > 1:\n",
    "                context = context[1:] + [token]\n",
    "           \n",
    "            string = string + \" \" + token\n",
    "\n",
    "            if token == \"<END>\":\n",
    "                context = [\"<START>\" for i in range(self.n - 1)]\n",
    "\n",
    "        return(string)\n",
    "\n",
    "    \n",
    "    def perplexity(self, sentence):\n",
    "        \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            sentence - A string\n",
    "        Output:\n",
    "            Perplexity of the string, given the dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        ngram = ngrams(self.n, tokenize(sentence))\n",
    "        perp = 0\n",
    "\n",
    "        for gram in ngram:\n",
    "            perp += math.log((1/self.prob(gram[0], gram[1])))\n",
    "\n",
    "        return((math.e ** perp)**(1/len(ngram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_model(n, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        n - Number of previous tokens to include\n",
    "        path - File path of text\n",
    "    Output:\n",
    "        n_gram_obj - Object of type NgramModel trained on given text\n",
    "    \"\"\"\n",
    "    \n",
    "    file_path = open(path, \"r\")\n",
    "    n_gram_obj = NgramModel(n)\n",
    "\n",
    "    for line in file_path:\n",
    "        n_gram_obj.update(line.replace(\"\\n\", \" \"))\n",
    "\n",
    "    return(n_gram_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Alas , I can befall a scene is as you will not laugh in the desert that alarmed at Servox and the recess of my skin was sufficient for one of the overthrow of my undertaking or at the sun was myself , which I entered , stretched before me'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = create_ngram_model(2, \"frankenstein.txt\")\n",
    "m.random_text(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' At first I started back , unable to believe that it was indeed I who was reflected in the mirror ; and when I awoke , and my first care was to procure the whole works of this author , and afterwards of Paracelsus and Albertus Magnus . <END> I'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = create_ngram_model(5, \"frankenstein.txt\")\n",
    "m.random_text(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' But even human sympathies were not sufficient to satisfy his eager mind . <END> I sank to the ground , and my injurer , with increased swiftness , escaped into the wood . <END> Why did you confess ? <END> He began his lecture by a recapitulation of the history'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = create_ngram_model(10, \"frankenstein.txt\")\n",
    "m.random_text(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I wish to soothe him , yet can I counsel one so infinitely miserable , so destitute of every hope of consolation , to live ? <END> He could not help regarding my exclamation as a presumption of my guilt and said in rather a severe tone , \" I'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = create_ngram_model(20, \"frankenstein.txt\")\n",
    "m.random_text(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' But here also I am checked . <END> He felt as if he had been transported to fairy - land and enjoyed a happiness seldom tasted by man . <END> From you only could I hope for succour , although towards you I felt no sentiment but that of hatred'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = create_ngram_model(50, \"frankenstein.txt\")\n",
    "m.random_text(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
