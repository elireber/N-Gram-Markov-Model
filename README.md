# N-Gram-Markov-Model

This project is a practice in novel text generation using an N-Gram Markov Model.  After being trained on the dataset (Frankenstein.txt), the model is used to generate novel sentences that follow the linguistic distribution of the actual Frankenstein text, but do not actually appear in the story itself.  It can be seen that as the value of n increases, the sentences tend to make more "sense", as the perplexity of the generated sentence will decrease. 

### Folder Contents:
Code - Jupyter Notebook containing Python code for model and results of generation with different values of n

Data - Text of Frakenstein, used to train model and generate novel sentences
